# Bu kodda, K-Fold kullanarak veri setini 5 katmana bÃ¶lecek ve her bir katmanda farklÄ± k deÄŸerleri iÃ§in
# modelin doÄŸruluÄŸunu hesaplayarak en iyi k deÄŸerini belirleyeceÄŸiz.
#
#
# K-Fold Cross-Validation: Veri setini 5 katmana bÃ¶ler ve her katmanda eÄŸitim ve test iÅŸlemi yaparak sonuÃ§larÄ± ortalamalar.
# KNN Modeli: FarklÄ± ğ‘˜ deÄŸerleriyle KNN modelini Ã§alÄ±ÅŸtÄ±rÄ±r ve her ğ‘˜ iÃ§in performans hesaplar.
# En Ä°yi k: Hangi ğ‘˜?
# k deÄŸerinin en dÃ¼ÅŸÃ¼k hata oranÄ±na sahip olduÄŸunu bulur.
#

import numpy as np
import pandas as pd
from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_iris  # Ã–rnek veri seti, kendi veri setinizi buraya koyabilirsiniz
import matplotlib.pyplot as plt

df = pd.read_csv('files/happydata.csv')
X = df.drop('happy', axis=1)
y = df['happy']

# data = load_iris()
# X = data.data
# y = data.target

# Veriyi Ã¶lÃ§eklendir
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# KNN iÃ§in farklÄ± k deÄŸerleri deneyeceÄŸiz
k_range = range(1, 21)  # 1 ile 20 arasÄ±ndaki k deÄŸerlerini deniyoruz
error_rates = []  # Hata oranlarÄ±nÄ± saklamak iÃ§in liste

# 5 katlÄ± Cross-Validation kullanarak farklÄ± k'lar iÃ§in hata oranÄ±nÄ± hesapla
for k in k_range:
    # knn = KNeighborsClassifier(n_neighbors=k)
    knn = KNeighborsClassifier(n_neighbors=k, metric='manhattan')

    # 5 katlÄ± cross-validation ile doÄŸruluk hesapla (scoring='accuracy' deÄŸil, 'neg_mean_squared_error' kullanacaÄŸÄ±z)
    # 'neg_mean_squared_error' hata oranÄ± iÃ§in negatif doÄŸruluÄŸu dÃ¶ndÃ¼rÃ¼r.
    scores = cross_val_score(knn, X_scaled, y, cv=5, scoring='neg_mean_squared_error')

    # Hata oranÄ±nÄ± hesapla (negatif skorlar olduÄŸu iÃ§in negatif iÅŸareti kaldÄ±rÄ±yoruz)
    error_rate = -np.mean(scores)
    error_rates.append(error_rate)

# En iyi k'yÄ± bul
best_k = k_range[np.argmin(error_rates)]  # En dÃ¼ÅŸÃ¼k hata oranÄ±na sahip k
best_error_rate = np.min(error_rates)  # En dÃ¼ÅŸÃ¼k hata oranÄ±

# SonuÃ§larÄ± yazdÄ±r
print(f"En iyi k deÄŸeri: {best_k}")
print(f"En iyi hata oranÄ±: {best_error_rate:.4f}")

# Hata oranlarÄ±nÄ± Ã§izdirme
plt.figure(figsize=(8, 5))
plt.plot(k_range, error_rates, marker='o', linestyle='dashed', color='r')
plt.xticks(k_range)
plt.yticks(np.round(np.linspace(min(error_rates), max(error_rates), num=10), 4))
plt.xlabel("K DeÄŸeri")
plt.ylabel('Hata OranÄ± (Error Rate)')
# plt.title('KNN iÃ§in K-Fold Cross-Validation ile \n KNN AlgoritmasÄ±nda En Ä°yi K DeÄŸerini Bulma (Hata OranÄ±)')
plt.title('KNN iÃ§in K-Fold Cross-Validation ile \n KNN AlgoritmasÄ±nda En Ä°yi K DeÄŸerini Bulma (Hata OranÄ±) (Manhattan)')

plt.grid()
plt.show()

